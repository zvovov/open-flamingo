{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "zz4MO-SK44Q8",
      "metadata": {
        "id": "zz4MO-SK44Q8"
      },
      "source": [
        "# Download VQAv2 dataset images\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "gkeVDgRUrn23",
      "metadata": {
        "id": "gkeVDgRUrn23"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The syntax of the command is incorrect.\n",
            "'wget' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n",
            "'wget' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n",
            "'unzip' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n",
            "'unzip' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "#!wget http://images.cocodataset.org/zips/test2015.zip\n",
        "!mkdir /content/vqav2/\n",
        "\n",
        "!wget http://images.cocodataset.org/zips/train2014.zip\n",
        "!wget http://images.cocodataset.org/zips/val2014.zip\n",
        "\n",
        "!unzip /content/train2014.zip -d /content/vqav2/\n",
        "!unzip /content/val2014.zip -d /content/vqav2/"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5EgnyV__43BL",
      "metadata": {
        "id": "5EgnyV__43BL"
      },
      "source": [
        "# Install custom open_flamingo model with VQAv2 dataset questions and answers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Y7ZMDD2QDyOG",
      "metadata": {
        "id": "Y7ZMDD2QDyOG"
      },
      "outputs": [],
      "source": [
        "!rm -rf /content/open_flamingo\n",
        "!git clone https://github.com/Lavrenti-Mikaelyan/open_flamingo.git\n",
        "\n",
        "!unzip /content/open_flamingo/vqav2/v2_Questions_Train_mscoco.zip -d /content/vqav2/\n",
        "!unzip /content/open_flamingo/vqav2/v2_Questions_Val_mscoco.zip -d /content/vqav2/\n",
        "#!unzip /content/v2_Questions_Test_mscoco.zip -d /content/VQA/Questions\n",
        "\n",
        "!unzip /content/open_flamingo/vqav2/v2_Annotations_Train_mscoco.zip -d /content/vqav2\n",
        "!unzip /content/open_flamingo/vqav2/v2_Annotations_Val_mscoco.zip -d /content/vqav2\n",
        "\n",
        "!pip install scikit-image matplotlib\n",
        "!pip install -r /content/open_flamingo/requirements.txt\n",
        "!pip install -r /content/open_flamingo/requirements-eval.txt\n",
        "from huggingface_hub import hf_hub_download"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sRfOuMn57G_X",
      "metadata": {
        "id": "sRfOuMn57G_X"
      },
      "source": [
        "# Run evaluation on pre-trained Open-Flamingo\n",
        "Needs 16GB GPU, runs 0, 4, 8 shot experiments\n",
        "Needs more GPU for 16+ shot\n",
        "Uses Open Clip Vit-L/14 and MPT-1B-RedPajama-200B\n",
        "Tests on 4000 VQAv2 samples for each shot config to to limit runtime <2 hrs in total\n",
        "\n",
        "Prelim results:\n",
        "\n",
        "  0 shot - 43.53 VQA score\n",
        "\n",
        "  4 shot - 44.66 VQA score\n",
        "\n",
        "  8 shot - 44.75 VQA score\n",
        "\n",
        "  (comparable/close to Open_Flamingo result, can increase sample count to get true accuracy)\n",
        "\n",
        "This is a Flamingo-3B model. Compared to the performance of the same model in the Flamingo paper, 4-shot VQA is performs about %8 worse. I attribute this to different vision encoder and LLM choices in paper vs Open Flamingo, different pretraining dataset (M3W vs mmc4).\n",
        "\n",
        "Note, that even the developers of Open Flamingo admit that their models achieve only 80-89% of what the origial Flamingo results were.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "PggHtdLqvZh2",
      "metadata": {
        "id": "PggHtdLqvZh2"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'hf_hub_download' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\pran\\Documents\\ck\\nlp_project\\open-flamingo\\eval\\eval_script(VQAv2).ipynb Cell 6\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/pran/Documents/ck/nlp_project/open-flamingo/eval/eval_script%28VQAv2%29.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/pran/Documents/ck/nlp_project/open-flamingo/eval/eval_script%28VQAv2%29.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m checkpoint_path \u001b[39m=\u001b[39m hf_hub_download(\u001b[39m\"\u001b[39m\u001b[39mopenflamingo/OpenFlamingo-3B-vitl-mpt1b\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcheckpoint.pt\u001b[39m\u001b[39m\"\u001b[39m, local_dir\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m/content/open_flamingo\u001b[39m\u001b[39m'\u001b[39m, local_dir_use_symlinks\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/pran/Documents/ck/nlp_project/open-flamingo/eval/eval_script%28VQAv2%29.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(checkpoint_path)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/pran/Documents/ck/nlp_project/open-flamingo/eval/eval_script%28VQAv2%29.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m sys\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39minsert(\u001b[39m0\u001b[39m,\u001b[39m'\u001b[39m\u001b[39m/content/open_flamingo/open_flamingo\u001b[39m\u001b[39m'\u001b[39m)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'hf_hub_download' is not defined"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "checkpoint_path = hf_hub_download(\"openflamingo/OpenFlamingo-3B-vitl-mpt1b\", \"checkpoint.pt\", local_dir='/content/open_flamingo', local_dir_use_symlinks=False)\n",
        "print(checkpoint_path)\n",
        "sys.path.insert(0,'/content/open_flamingo/open_flamingo')\n",
        "\n",
        "!chmod +x /content/open_flamingo/open_flamingo/scripts/run_eval.sh\n",
        "!/content/open_flamingo/open_flamingo/scripts/run_eval.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "os.environ['PYTHONFAULTHANDLER'] = '1'\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '0'\n",
        "os.environ['PYTHONPATH']=\"/env/python:open_flamingo\"\n",
        "\n",
        "print(os.environ['PYTHONFAULTHANDLER'])\n",
        "print(os.environ['CUDA_LAUNCH_BLOCKING'])\n",
        "print(os.environ['PYTHONPATH'])\n",
        "\n",
        "checkpoint_path = hf_hub_download(\"openflamingo/OpenFlamingo-3B-vitl-mpt1b\", \"checkpoint.pt\", local_dir='/content/open_flamingo', local_dir_use_symlinks=False)\n",
        "print(checkpoint_path)\n",
        "sys.path.insert(0,'/content/open_flamingo/open_flamingo')\n",
        "\n",
        "!python /content/open_flamingo/open_flamingo/eval/evaluate.py \\\n",
        "    --vision_encoder_path ViT-L-14 \\\n",
        "    --vision_encoder_pretrained openai\\\n",
        "    --lm_path anas-awadalla/mpt-1b-redpajama-200b \\\n",
        "    --lm_tokenizer_path anas-awadalla/mpt-1b-redpajama-200b \\\n",
        "    --cross_attn_every_n_layers 1 \\\n",
        "    --checkpoint_path \"/content/open_flamingo/checkpoint.pt\" \\\n",
        "    --results_file \"results.json\" \\\n",
        "    --precision \"fp32\" \\\n",
        "    --batch_size 16 \\\n",
        "    --shots 4 \\\n",
        "    --num_samples 8000 \\\n",
        "    --eval_vqav2 \\\n",
        "    --vqav2_train_image_dir_path \"/content/vqav2/train2014\" \\\n",
        "    --vqav2_train_annotations_json_path \"/content/vqav2/v2_mscoco_train2014_annotations.json\" \\\n",
        "    --vqav2_train_questions_json_path \"/content/vqav2/v2_OpenEnded_mscoco_train2014_questions.json\" \\\n",
        "    --vqav2_test_image_dir_path \"/content/vqav2/val2014\" \\\n",
        "    --vqav2_test_annotations_json_path \"/content/vqav2/v2_mscoco_val2014_annotations.json\" \\\n",
        "    --vqav2_test_questions_json_path \"/content/vqav2/v2_OpenEnded_mscoco_val2014_questions.json\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
